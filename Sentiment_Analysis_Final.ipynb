{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import seaborn as sns\n",
    "from numpy import nan\n",
    "from bs4 import BeautifulSoup    \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from math import sqrt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Training set\n",
    "training_set= pd.read_csv('dataset.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 156060 entries, 0 to 156059\nData columns (total 4 columns):\nPhraseId      156060 non-null int64\nSentenceId    156060 non-null int64\nPhrase        156060 non-null object\nSentiment     156060 non-null int64\ndtypes: int64(3), object(1)\nmemory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#Training set Summary\n",
    "training_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Snippet of training set\n",
    "training_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set shape: ', (156060, 4))\n"
     ]
    }
   ],
   "source": [
    "# As a sanity check, we print out the size of the training data.\n",
    "print('Training set shape: ', training_set.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set shape: ', (5000, 4))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subsample the data for more efficient code execution in this exercise\n",
    "num_train=50000\n",
    "training_set = training_set[0:num_train]\n",
    "print('Training set shape: ', training_set.shape)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>somewhat negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>somewhat negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new column that transforms sentiment (integer) to a phrase \n",
    "Sentiment_words=[]\n",
    "for row in training_set['Sentiment']:\n",
    "    if row ==0:\n",
    "        Sentiment_words.append('negative')\n",
    "    elif row == 1:\n",
    "        Sentiment_words.append('somewhat negative')\n",
    "    elif row == 2:\n",
    "        Sentiment_words.append('neutral')\n",
    "    elif row == 3:\n",
    "        Sentiment_words.append('somewhat positive')\n",
    "    elif row == 4:\n",
    "        Sentiment_words.append('positive')\n",
    "        \n",
    "training_set['Sentiment_words'] = Sentiment_words\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "somewhat negative     777\nsomewhat positive     898\npositive              251\nnegative              155\nneutral              2919\ndtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count appearances of each of the 5 Sentiment Phrases\n",
    "word_count=pd.value_counts(training_set['Sentiment_words'].values, sort=False)\n",
    "word_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing steps\n",
    "def review_to_words(raw_review): \n",
    "    review =raw_review\n",
    "    review = re.sub('[^a-zA-Z]', ' ',review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    review = [lemmatizer.lemmatize(w) for w in review if not w in set(stopwords.words('english'))]\n",
    "    return (' '.join(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms column phrase of the training data into a list. Each element of the list is a phrase which is preprocessed \n",
    "#by the review_to_words function\n",
    "vocabulary= []\n",
    "for i in range(0, training_set.shape[0]):\n",
    "    vocabulary.append(review_to_words(training_set['Phrase'][i]))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_words</th>\n",
       "      <th>new_Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>somewhat negative</td>\n",
       "      <td>series escapade demonstrating adage good goose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>series escapade demonstrating adage good goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_words</th>\n",
       "      <th>new_Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>somewhat negative</td>\n",
       "      <td>series escapade demonstrating adage good goose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>series escapade demonstrating adage good goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We create a new column in our training set, called new_Phrase, which is our previous preprocessed list.\n",
    "training_set['new_Phrase']=vocabulary\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_words</th>\n",
       "      <th>new_Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>somewhat negative</td>\n",
       "      <td>series escapade demonstrating adage good goose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>series escapade demonstrating adage good goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_words</th>\n",
       "      <th>new_Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>somewhat negative</td>\n",
       "      <td>series escapade demonstrating adage good goose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>series escapade demonstrating adage good goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We delete the previous column \"Phrase\" from our training set.\n",
    "training_set.drop(['Phrase'],axis=1,inplace=True)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the tokens for each phrase\n",
    "phrases_tokens = []\n",
    "for phrase in training_set['new_Phrase'][:num_train]:\n",
    "    phrases_tokens.append(nltk.word_tokenize(phrase) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the tag for each token\n",
    "tags = []\n",
    "for token in phrases_tokens:\n",
    "    tags.append(nltk.pos_tag(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "scores = []\n",
    "# in each loop the words of each sentence are analyzed\n",
    "for index, sentence in enumerate(tags):\n",
    "    scores.append([])\n",
    "\n",
    "    for tagged_word in sentence:\n",
    "\n",
    "        #create new tag (a:adjective or v:verb)\n",
    "        ntag = None\n",
    "\n",
    "        if tagged_word[1].startswith('JJ'):\n",
    "            ntag = 'a'\n",
    "        elif tagged_word[1].startswith('NN'):\n",
    "            ntag = 'n'\n",
    "        elif tagged_word[1].startswith('V'):\n",
    "            ntag = 'v'\n",
    "        elif tagged_word[1].startswith('R'):\n",
    "            ntag = 'r'\n",
    "        else:\n",
    "            ntag = ''\n",
    "\n",
    "        if (ntag != None):\n",
    "            # Getting average of all possible synsets\n",
    "            synsets = swn.senti_synsets(tagged_word[0], ntag)\n",
    "            \n",
    "            #score keeps sum(pos-neg) for each synset\n",
    "            score = 0\n",
    "            if (len(synsets) > 0):\n",
    "                for s in synsets:\n",
    "                    score += s.pos_score() - s.neg_score()\n",
    "                #the final score for a word is the average score of all its synsets\n",
    "                scores[index].append(score / len(synsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiments for each sentence\n",
    "sentence_sent = []\n",
    "\n",
    "#sentiment for each sentence is the average sentiment of its words\n",
    "for score in scores:\n",
    "    if len(score)==0:\n",
    "        #if sentnece has no words then append it as neutral\n",
    "        sentence_sent.append(0)\n",
    "    else:\n",
    "        #the sentiment of a sentence is the average sentiment of its words\n",
    "        sentence_sent.append(sum([word_score for word_score in score]) / len(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions\n",
    "pred = []\n",
    "for sen in sentence_sent:\n",
    "    if sen <-0.6:\n",
    "        pred.append('negative')\n",
    "    elif sen<-0.2:\n",
    "        pred.append('somewhat negative')\n",
    "    elif sen<0.2:\n",
    "        pred.append('neutral')\n",
    "    elif sen<0.6:\n",
    "        pred.append('somewhat positive')\n",
    "    else:\n",
    "        pred.append('positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   13  133    6    1]\n [   7   66  661   42    1]\n [   5   91 2667  149    7]\n [   0   14  760  116    8]\n [   1    2  203   43    2]]\n"
     ]
    }
   ],
   "source": [
    "#compute the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf =  confusion_matrix( training_set['Sentiment_words'][:num_train] , pred,\n",
    "                  labels=[\"negative\", \"somewhat negative\", \"neutral\", \"somewhat positive\", \"positive\"])\n",
    "\n",
    "print conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = [   2   66 2667  116    2] \n FN = [  13  120 1757  240   17] \n FP = [153 711 252 782 249] \n TN = [4832 4103  324 3862 4732]\n"
     ]
    }
   ],
   "source": [
    "#compute TP, TN, FP, FN\n",
    "import numpy as np\n",
    "FP = conf.sum(axis=1) - np.diag(conf)\n",
    "FN = conf.sum(axis=0) - np.diag(conf)\n",
    "TP = np.diag(conf)\n",
    "TN = np.sum(conf) - (FP + FN + TP)\n",
    "print \"TP = %s \\n FN = %s \\n FP = %s \\n TN = %s\" %(TP, FN, FP, TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate metrics for each label\n",
    "def calc_measures(TP, FN, FP, TN, index):\n",
    "    Prec = float(TP[index]) / (TP[index] + FP[index])\n",
    "    Acc = float(TP[index]) / (TP[index] + FP[index] + FN[index] + TN[index])\n",
    "    Rec = float(TP[index]) / (TP[index] + FN[index])\n",
    "    F1 = 2 * float(Rec * Prec) / (Rec + Prec)\n",
    "    return Prec, Acc, Rec, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for class: negative\nPrec = 1.29032258065 \n Acc = 0.04 \n Rec = 13.3333333333 \n F1 = 2.35294117647\nMetrics for class: somewhat negative\nPrec = 8.49420849421 \n Acc = 1.32 \n Rec = 35.4838709677 \n F1 = 13.707165109\nMetrics for class: neutral\nPrec = 91.3669064748 \n Acc = 53.34 \n Rec = 60.2848101266 \n F1 = 72.6406101049\nMetrics for class: somewhat positive\nPrec = 12.9175946548 \n Acc = 2.32 \n Rec = 32.5842696629 \n F1 = 18.5007974482\nMetrics for class: positive\nPrec = 0.796812749004 \n Acc = 0.04 \n Rec = 10.5263157895 \n F1 = 1.48148148148\nMeasure for class: negative\nPrec = 1.29032258065 \n Acc = 0.04 \n Rec = 13.3333333333 \n F1 = 2.35294117647\nMeasure for class: somewhat negative\nPrec = 8.49420849421 \n Acc = 1.32 \n Rec = 35.4838709677 \n F1 = 13.707165109\nMeasure for class: neutral\nPrec = 91.3669064748 \n Acc = 53.34 \n Rec = 60.2848101266 \n F1 = 72.6406101049\nMeasure for class: somewhat positive\nPrec = 12.9175946548 \n Acc = 2.32 \n Rec = 32.5842696629 \n F1 = 18.5007974482\nMeasure for class: positive\nPrec = 0.796812749004 \n Acc = 0.04 \n Rec = 10.5263157895 \n F1 = 1.48148148148\n"
     ]
    }
   ],
   "source": [
    "#calculate average precission, accuracy, recall, F1 for each class\n",
    "avgPrec = avgAcc = avgRec = avgF1 = 0\n",
    "for idx, sent in enumerate([\"negative\", \"somewhat negative\", \"neutral\", \"somewhat positive\", \"positive\"]):\n",
    "    print \"Metrics for class: %s\" %(sent)\n",
    "    Prec, Acc, Rec, F1 = calc_measures(TP, FN, FP, TN, idx)\n",
    "    print \"Prec = %s \\n Acc = %s \\n Rec = %s \\n F1 = %s\" %(Prec*100, Acc*100, Rec*100, F1*100)\n",
    "    avgPrec = avgPrec+Prec\n",
    "    avgAcc = avgAcc+Acc\n",
    "    avgRec = avgRec+Rec\n",
    "    avgF1 = avgF1+F1\n",
    "\n",
    "avgPrec = avgAcc = avgRec = avgF1 = 0\n",
    "for idx, sent in enumerate([\"negative\", \"somewhat negative\", \"neutral\", \"somewhat positive\", \"positive\"]):\n",
    "    print \"Measure for class: %s\" %(sent)\n",
    "    Prec, Acc, Rec, F1 = calc_measures(TP, FN, FP, TN, idx)\n",
    "    print \"Prec = %s \\n Acc = %s \\n Rec = %s \\n F1 = %s\" %(Prec*100, Acc*100, Rec*100, F1*100)\n",
    "    avgPrec = avgPrec+Prec\n",
    "    avgAcc = avgAcc+Acc\n",
    "    avgRec = avgRec+Rec\n",
    "    avgF1 = avgF1+F1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average statistics\nAverage Prec = 22.9731689907 \n Average Acc = 57.06 \n Average Rec = 30.442519976 \n Average F1 = 21.736599064\n"
     ]
    }
   ],
   "source": [
    "#compute average metrics\n",
    "avgPrec = float(avgPrec)/5\n",
    "avgAcc = float(avgAcc)\n",
    "avgRec = float(avgRec)/5\n",
    "avgF1 = float(avgF1)/5\n",
    "print \"Average statistics\"\n",
    "print \"Average Prec = %s \\n Average Acc = %s \\n Average Rec = %s \\n Average F1 = %s\" %(avgPrec*100, avgAcc*100, avgRec*100, avgF1*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'abandoned', u'abandoned still', u'abel', u'abel ferrara', u'aborted', u'aborted attempt', u'absolute', u'absolute joy', u'absorbing', u'absorbing character', u'absorbing documentary', u'accent', u'accent rrb', u'accurate', u'accurate depiction', u'achieved', u'achieved lottery', u'achievement', u'achievement director', u'achieving', u'achieving honest', u'across', u'across relic', u'acting', u'acting workshop', u'action', u'action flick', u'action scene', u'action screenwriter', u'action speed', u'actor', u'actor exercise', u'actor never', u'actor performance', u'actor well', u'actress', u'actress trying', u'actually', u'actually rather', u'adage', u'adage good', u'adaptation', u'adaptation mary', u'adolescent', u'adolescent audience', u'adrenaline', u'adrenaline jolt', u'affecting', u'affecting portrait', u'affection', u'affection original', u'age', u'age first', u'agers', u'agers stumble', u'aggressive', u'aggressive self', u'aid', u'aid wisecracking', u'aim', u'aim funny', u'aim poetry', u'airless', u'airless cinematic', u'almost', u'almost feel', u'almost indecipherable', u'alone', u'alone abandoned', u'alone could', u'also', u'also fully', u'also good', u'also imbued', u'also prisoner', u'also tragedy', u'although', u'although fairly', u'amateurish', u'amateurish filmmaking', u'amazing', u'amazing slapstick', u'ambition', u'ambition say', u'america', u'america masterful', u'american', u'amiable', u'amiable unfocused', u'amid', u'amid shock', u'amount', u'amount much', u'amuses', u'amuses none', u'amusing', u'analyze', u'analyze one', u'another', u'another believe', u'antic', u'antic perverse', u'anything', u'anything humorous', u'apart', u'apart movie', u'apart reporting', u'appreciate', u'appreciate one', u'approach', u'approach detailing', u'appropriate', u'appropriate structure', u'around', u'around screaming', u'arrives', u'arrives impeccable', u'arriving', u'arriving particularly', u'art', u'art ethic', u'art ever', u'art flick', u'arthur', u'arthur schnitzler', u'artist', u'artist simply', u'arty', u'ask', u'ask permission', u'assault', u'assault embarrassingly', u'attempt', u'attempt waking', u'attract', u'attract upscale', u'attraction', u'attraction eventually', u'attracts', u'attracts young', u'audience', u'audience child', u'audience demanding', u'audience hungry', u'avenger', u'avenger wild', u'avoid', u'avoid solving', u'aware', u'aware coolness', u'awkwardly', u'awkwardly contrived', u'back', u'back forth', u'bad', u'bad bluescreen', u'bad boy', u'bad make', u'bagatelle', u'bagatelle play', u'banality', u'barely', u'barely clad', u'barely defensible', u'barely something', u'barrel', u'bartlett', u'bartlett familiar', u'base', u'base melodrama', u'baseball', u'baseball movie', u'bathtub', u'battle', u'battle will', u'beach', u'beach adrenaline', u'beaten', u'beaten pulp', u'beautiful', u'beautiful star', u'beautifully', u'beautifully crafted', u'becomes', u'becomes narrative', u'becomes study', u'begging', u'begging foot', u'believe', u'believe put', u'beneath', u'beneath otherwise', u'best', u'best indie', u'best performance', u'best war', u'bet', u'bet make', u'betrayal', u'betrayal deceit', u'better', u'better judgment', u'better summer', u'beyond', u'beyond comprehension', u'beyond wilde', u'big', u'big screen', u'big splash', u'bigger', u'bigger scrapbook', u'bilingual', u'bilingual charmer', u'bind', u'bit', u'bit heavy', u'bizarre', u'bizarre sort', u'blab', u'blame', u'blame making', u'blockbuster', u'blockbuster endure', u'bloody', u'bloody sunday', u'blowing', u'blowing empty', u'blown', u'blown size', u'bluescreen', u'bluescreen ultra', u'body', u'body myrtle', u'bogged', u'bogged earnest', u'boilerplate', u'boilerplate start', u'bonus', u'bonus feature', u'bottom', u'bottom cracker', u'bottom pool', u'bout', u'bout barely', u'boy', u'boy weirdo', u'break', u'break heart', u'brief', u'brief minute', u'brilliant', u'brilliant gag', u'brilliantly', u'brilliantly played', u'brush', u'brush humanity', u'budding', u'budding demon', u'budget', u'budget movie', u'bulk', u'bulk movie', u'bunch', u'bunch exotic', u'burr', u'burr steer', u'bygone', u'bygone era', u'call', u'call film', u'call prevention', u'camera', u'camera way', u'camp', u'camp comprehension', u'campanella', u'campanella get', u'candy', u'candy coat', u'capability', u'capability soothe', u'caper', u'capped', u'capped pointless', u'capture', u'capture innocence', u'card', u'card live', u'care', u'care funny', u'carry', u'carry effortlessly', u'cartoon', u'cartoon feel', u'case', u'case letting', u'case study', u'catholic', u'catholic really', u'cattaneo', u'cattaneo followed', u'cause', u'celebrated', u'celebrated irish', u'center', u'center wrong', u'chabrol', u'chabrol camera', u'champion', u'champion ultimately', u'chance', u'chance distort', u'changing', u'changing lane', u'chapter', u'chapter life', u'character', u'character deeply', u'character life', u'character like', u'character peppering', u'character piece', u'character undergoing', u'character veiling', u'charm', u'charm five', u'charmer', u'charmer like', u'charming', u'charming funny', u'cheap', u'cheap movie', u'cheesy', u'cheesy dialogue', u'chemical', u'chemical bunch', u'child', u'child film', u'child without', u'childhood', u'childhood dream', u'chimp', u'chimp blown', u'chimp lot', u'cho', u'cho face', u'chooses', u'chooses champion', u'christopher', u'christopher doyle', u'chuck', u'chuck norris', u'chuckle', u'chuckle give', u'cinema', u'cinema paradiso', u'cinematic', u'cinematic distraction', u'cinematic experience', u'cinematic shell', u'cinematographer', u'cinematographer christopher', u'circumstance', u'circumstance beautiful', u'city', u'city religious', u'civic', u'civic virtue', u'clad', u'clad body', u'claude', u'claude chabrol', u'clearly', u'clearly mean', u'clever', u'clever credit', u'cliche', u'cliche call', u'cliche considerable', u'cliched', u'cliched dialogue', u'clip', u'clip film', u'closure', u'closure open', u'clumsy', u'clumsy key', u'clunky', u'clunky tv', u'co', u'co writer', u'coasting', u'coat', u'coat pat', u'coma', u'coma like', u'combination', u'combination ethnography', u'come', u'come across', u'comedy', u'comedy boilerplate', u'comedy drama', u'comedy equivalent', u'comedy steven', u'comedy two', u'comic', u'comic antic', u'comic course', u'coming', u'coming miramax', u'common', u'common line', u'companion', u'companion mr', u'company', u'compelling', u'compelling reason', u'compelling story', u'completely', u'completely miss', u'complication', u'comprehensible', u'comprehensible dummy', u'comprehension', u'comprehension even', u'comprehension made', u'compressed', u'compressed evanescent', u'compromise', u'computer', u'computer generated', u'concept', u'concept film', u'conclusion', u'condition', u'confrontation', u'connected', u'connected string', u'connection', u'connection steven', u'consciousness', u'considerable', u'considerable dash', u'considers', u'considers cliched', u'consistently', u'consistently unimaginative', u'consoled', u'consoled art', u'constructed', u'constructed narrative', u'contrived', u'contrived exercise', u'contrived pastiche', u'contrived sequel', u'converted', u'convoluted', u'convoluted journey', u'convolution', u'convolution feel', u'cool', u'cool actor', u'cooler', u'cooler pg', u'coolness', u'corny', u'corny dialogue', u'corny examination', u'cost', u'cost moral', u'could', u'could force', u'could hate', u'could young', u'couple', u'couple aborted', u'couple sense', u'courage', u'courage idea', u'course', u'course unintentional', u'cowering', u'cowering begging', u'cracker', u'cracker barrel', u'cradle', u'cradle character', u'crafted', u'crafted engaging', u'crass', u'crass contrived', u'created', u'created monster', u'creating', u'creating scrapbook', u'creature', u'creature feature', u'creature get', u'credit', u'credit roll', u'crime', u'crime hell', u'crisis', u'cross', u'cross made', u'cross toxic', u'culture', u'culture compressed', u'curiosity', u'curiosity factor', u'cut', u'cut film', u'damned', u'danang', u'danang reveals', u'dangerous', u'dangerous game', u'dared', u'dared mess', u'dark', u'dark gritty', u'dark moment', u'dark thriller', u'darkness', u'darkness light', u'dash', u'date', u'daughter', u'daughter danang', u'david', u'david kendall', u'david mamet', u'day', u'day plodding', u'deal', u'deal corny', u'death', u'deceit', u'deceit murder', u'decent', u'decent material', u'deconstruction', u'deconstruction gay', u'decter', u'deep', u'deep shelf', u'deepest', u'deepest tragedy', u'deeply', u'deeply thought', u'deeply unsettling', u'defend', u'defend frothing', u'defensible', u'defensible sexual', u'definite', u'definite room', u'degree', u'degree randomness', u'delectable', u'delectable diversion', u'delicate', u'delicate forcefulness', u'delicious', u'delicious pulpiness', u'delivered', u'delivers', u'delivers perfect', u'demanding', u'demanding regular', u'demon', u'demon within', u'demonstrating', u'demonstrating adage', u'denouement', u'denouement high', u'deok', u'deok seems', u'depiction', u'depiction depression', u'depression', u'designed', u'designed garner', u'despite', u'despite gratuitous', u'despite mainland', u'detail', u'detail right', u'detail time', u'detailing', u'detailing chapter', u'development', u'development processed', u'devolves', u'devolves bizarre', u'devos', u'devos delivers', u'dialogue', u'dialogue highlight', u'dialogue perverse', u'dialogue preposterous', u'different', u'different yet', u'diner', u'directed', u'directed barely', u'direction', u'direction keep', u'director', u'director burr', u'director cut', u'director malcolm', u'director peter', u'director released', u'director trying', u'disagree', u'disagree honestly', u'disappointed', u'discerned', u'discerned producer', u'disney', u'disney scrape', u'distort', u'distort perspective', u'distract', u'distract solution', u'distraction', u'distraction impressed', u'disturb', u'disturb work', u'diversion', u'dizzily', u'dizzily gorgeous', u'documentary', u'dog', u'dog lie', u'dog unless', u'double', u'double cross', u'downright', u'downright intoxicating', u'downright transparent', u'downward', u'downward thud', u'doyle', u'doyle understand', u'drag', u'drag soon', u'dragon', u'dragon real', u'drama', u'drama nearly', u'dramatic', u'dramatic even', u'dramatic thing', u'dramaturgy', u'dramaturgy stirring', u'drawing', u'drawn', u'drawn engaging', u'dream', u'dream martial', u'dream youth', u'drinker', u'drive', u'dull', u'dull subject', u'dull visually', u'dummy', u'dummy guide', u'dupe', u'dupe viewer', u'dvd', u'early', u'earnest', u'earnest dramaturgy', u'earnest offer', u'earnest thick', u'easily', u'easily substitutable', u'eccentricity', u'eccentricity failing', u'ed', u'ed decter', u'editing', u'editing bad', u'eerily', u'eerily accurate', u'effort', u'effort toward', u'effortlessly', u'effortlessly darkness', u'eight', u'eight legged', u'element', u'element alone', u'else', u'else show', u'embarrassingly', u'embarrassingly ham', u'emotion', u'emotion anything', u'emotional', u'emotional connection', u'emotionally', u'emotionally least', u'emotionally scattered', u'emphasizes', u'emphasizes quirky', u'employ', u'employ hollywood', u'empty', u'empty theatre', u'end', u'end much', u'end sounding', u'endless', u'endless assault', u'endure', u'endure last', u'engaging', u'engaging character', u'engaging filmmaking', u'engaging unpredictable', u'enjoy', u'enjoy big', u'enjoy tolstoy', u'entertaining', u'entertaining amusing', u'entertaining independent', u'entertaining summer', u'entertains', u'entertains much', u'entirely', u'entirely unprepared', u'enveloping', u'enveloping movie', u'epic', u'epic also', u'epic proportion', u'equivalent', u'equivalent saddam', u'equivalent teen', u'era', u'era convolution', u'eric', u'eric james', u'errol', u'errol morris', u'error', u'escapade', u'escapade demonstrating', u'escapism', u'escapism source', u'ethic', u'ethic cost', u'ethnography', u'ethnography intrigue', u'evanescent', u'evanescent seamless', u'even', u'even delectable', u'even dramatic', u'even fan', u'even non', u'even silly', u'eventually', u'eventually go', u'ever', u'ever made', u'ever revealed', u'every', u'every day', u'everyone', u'everyone involved', u'everything', u'everything expect', u'evil', u'evil monstrous', u'evoke', u'evoke memory', u'evokes', u'evokes style', u'ex', u'ex girlfriend', u'exalted', u'exalted tagline', u'examination', u'examination young', u'example', u'example kind', u'exclusively', u'exclusively converted', u'execution', u'execution story', u'exercise', u'exercise appropriate', u'exercise magic', u'exist', u'exist employ', u'exists', u'exists apart', u'exotic', u'exotic creature', u'expect', u'expect nothing', u'expedience', u'expense', u'expense paid', u'experience', u'experience predecessor', u'experience rhapsodizes', u'experimental', u'experimental storytelling', u'explosion', u'explosion start', u'extravagant', u'extravagant chance', u'extreme', u'extreme insanely', u'eye', u'eye idealistic', u'face', u'face rrb', u'factor', u'factor film', u'failing', u'failing ultimately', u'fails', u'fails make', u'fairly', u'fairly involving', u'fall', u'fall heist', u'fall piece', u'fallon', u'fallon pat', u'familial', u'familial tie', u'familiar', u'familiar quotation', u'famous', u'famous parent', u'fan', u'fan ismail', u'fan know', u'fantasia', u'fantasia love', u'far', u'far go', u'far much', u'fascinating', u'fascinating compelling', u'fascinating dark', u'fatal', u'fatal attraction', u'fatal script', u'favor', u'favor famous', u'fear', u'fear foible', u'feature', u'feature cartoon', u'feature dvd', u'feature fan', u'feature length', u'feel', u'feel director', u'feel like', u'feel movie', u'feel silly', u'ferrara', u'ferrara beaten', u'fi', u'fi deconstruction', u'fiction', u'fight', u'fight putting', u'fighter', u'fighter also', u'fighting', u'fighting fight', u'fillm', u'fillm modern', u'film', u'film aid', u'film aim', u'film also', u'film art', u'film bonus', u'film candy', u'film chimp', u'film clearly', u'film cooler', u'film corny', u'film despite', u'film end', u'film full', u'film hartley', u'film hews', u'film imax', u'film love', u'film make', u'film neither', u'film never', u'film refreshing', u'film rehash', u'film sneaky', u'film still', u'film truest', u'film wear', u'film whose', u'filmmaker', u'filmmaker post', u'filmmaker tian', u'filmmaker want', u'filmmaker would', u'filmmaking', u'filmmaking attract', u'filmmaking plainly', u'filmmaking visually', u'finally', u'finally coming', u'find', u'find movie', u'find new', u'find way', u'finish', u'fire', u'fire wo', u'first', u'first computer', u'first film', u'fisted', u'fisted sex', u'fit', u'five', u'five writer', u'flair', u'flair wax', u'flash', u'flash double', u'flatly', u'flatly david', u'flick', u'flick prof', u'flick sci', u'flickering', u'flickering reminder', u'focusing', u'focusing eccentricity', u'foible', u'followed', u'followed runaway', u'foot', u'foot scruffy', u'force', u'force scratch', u'force serve', u'forcefulness', u'forcefulness greene', u'forgettably', u'forgettably entertaining', u'form', u'forth', u'forth cradle', u'fortunately', u'fortunately still', u'frame', u'frame right', u'freak', u'freak partly', u'freak perfectly', u'freakish', u'freakish power', u'french', u'french shocker', u'fresh', u'fresh say', u'fresnadillo', u'fresnadillo something', u'frighten', u'frighten disturb', u'frothing', u'frothing ex', u'full', u'full monty', u'fully', u'fully example', u'fun', u'fun intoxicatingly', u'funnier', u'funnier director', u'funny', u'funny accent', u'funny lrb', u'funny middle', u'funny romantic', u'funny uplifting', u'furiously', u'furiously fear', u'furrow', u'furrow often', u'future', u'future america', u'gag', u'gag expense', u'gag occurs', u'gaitskill', u'gaitskill harrowing', u'gallo', u'gallo right', u'gamble', u'gamble publishing', u'game', u'game last', u'gander', u'gander occasionally', u'garner', u'garner film', u'gay', u'gay fantasia', u'gem', u'gem relay', u'generated', u'generated feature', u'generates', u'generates plot', u'generic', u'generic villain', u'gently', u'gently swaying', u'get', u'get bit', u'get bogged', u'get detail', u'get lot', u'get skin', u'get tone', u'giannini', u'giannini madonna', u'girlfriend', u'give', u'give best', u'give heart', u'give new', u'give reason', u'give way', u'glacial', u'glacial pacing', u'glorification', u'glorification manipulative', u'glorified', u'glorified martin', u'go', u'go ask', u'go film', u'go overboard', u'goal', u'goal frighten', u'going', u'going house', u'going maker', u'good', u'good bad', u'good execution', u'good film', u'good fun', u'good gander', u'good goose', u'good indication', u'good sense', u'good stuff', u'good time', u'goose', u'goose also', u'gorgeous', u'gorgeous companion', u'grace', u'grace call', u'graced', u'graced company', u'graphic', u'gratuitous', u'gratuitous cinematic', u'gray', u'gray equivalent', u'great', u'great acting', u'great deal', u'green', u'green rrb', u'greene', u'greene prose', u'grenade', u'grenade gag', u'gritty', u'gritty story', u'gross', u'gross comedy', u'groupie', u'growing', u'growing catholic', u'guess', u'guess affection', u'guessing', u'guide', u'guide something', u'guy', u'hack', u'hack work', u'ham', u'ham fisted', u'hampered', u'hampered paralyzed', u'handed', u'handed message', u'handle', u'happen', u'happen people', u'hard', u'hard mythic', u'hard say', u'hard time', u'harrison', u'harrowing', u'harrowing short', u'hartley', u'hartley created', u'hate', u'hate reason', u'hatfield', u'hatfield hick', u'head', u'heart', u'heart dog', u'heart single', u'heartfelt', u'heartfelt story', u'heavy', u'heavy handed', u'heed', u'heed mediocre', u'heist', u'heist much', u'hell', u'hell jaunt', u'hellish', u'hellish condition', u'hero', u'hero give', u'hero horror', u'hews', u'hews world', u'hick', u'hick make', u'high', u'high concept', u'high hilarity', u'high school', u'highlight', u'highlight radical', u'highly', u'highly recommended', u'hilarity', u'history', u'history culture', u'history offer', u'hit', u'hit three', u'hobby', u'hobby attracts', u'hold', u'hold society', u'hole', u'hole head', u'hollywood', u'hollywood action', u'hollywood kid', u'hollywood product', u'homage', u'homage tarantula', u'home', u'home french', u'honest', u'honest insight', u'honestly', u'honestly see', u'hong', u'hong kong', u'hooked', u'hooked delicious', u'hopeful', u'hopefully', u'hopefully set', u'horrendously', u'horrendously amateurish', u'horrifying', u'horrifying rrb', u'horror', u'horror hellish', u'horror movie', u'horton', u'horton director', u'host', u'host defend', u'house', u'house game', u'house party', u'humane', u'humane fighter', u'humanity', u'humanity psycho', u'humorous', u'hungry', u'hungry quality', u'hurt', u'hussein', u'hussein ready', u'ice', u'ice age', u'idea', u'idea technical', u'idealistic', u'idealistic kid', u'image', u'image war', u'imax', u'imax film', u'imax short', u'imbued', u'imbued strong', u'impeccable', u'impeccable pedigree', u'importance', u'importance earnest', u'important', u'important simply', u'impossible', u'impossible care', u'impossible get', u'impressed', u'impressed upon', u'improved', u'improvement', u'inadvertently', u'inadvertently evoke', u'incoherence', u'incoherence give', u'incompetent', u'incompetent conclusion', u'incomprehensible', u'indecipherable', u'indecipherable plot', u'independent', u'independent worth', u'indication', u'indication serious', u'indie', u'indie year', u'inducing', u'inducing nerve', u'indulgent', u'indulgent maddening', u'indulgent script', u'indulgent tirade', u'inept', u'inept big', u'inexorably', u'inexorably give', u'initial', u'initial strangeness', u'innocence', u'innocence budding', u'inoffensive', u'inoffensive actually', u'insanely', u'insanely violent', u'insight', u'insight relationship', u'inspired', u'instantly', u'instantly recognizable', u'instrument', u'instrument creating', u'intended', u'intended audience', u'interested', u'interested entertaining', u'interesting', u'interesting development', u'interesting find', u'intoxicating', u'intoxicatingly', u'intoxicatingly sexy', u'intrigue', u'intrigue betrayal', u'intrigue lrb', u'intriguing', u'intriguing downright', u'introspective', u'introspective entertaining', u'inventive', u'inventive fun', u'invigorating', u'invigorating surreal', u'involved', u'involved seems', u'involving', u'involving far', u'involving one', u'irish', u'irish playwright', u'ismail', u'ismail merchant', u'james', u'james eric', u'james horton', u'jaunt', u'jaunt purist', u'john', u'john ridley', u'joke', u'joke reek', u'jolt', u'jolt sudden', u'jones', u'jones tackled', u'journey', u'journey worth', u'joy', u'judge', u'judge one', u'judgment', u'judgment damned', u'juicy', u'juicy soap', u'keenly', u'keenly observed', u'keep', u'keep going', u'keep guessing', u'keep hooked', u'keep interested', u'kendall', u'kendall directed', u'key', u'key moment', u'ki', u'ki deok', u'kid', u'kid chooses', u'kid people', u'kim', u'kim ki', u'kind', u'kind lush', u'kind production', u'knock', u'knock enjoy', u'know', u'know cross', u'know evil', u'know handle', u'kong', u'kong movie', u'kooky', u'kooky overeager', u'kung', u'kung pow', u'lack', u'lack intrigue', u'lack quick', u'land', u'land prove', u'lane', u'lane try', u'largely', u'largely williams', u'last', u'last fall', u'last summer', u'latest', u'latest pop', u'latest vapid', u'law', u'law discerned', u'lawrence', u'lawrence indulgent', u'lawrence lovefest', u'lazy', u'lazy movie', u'le', u'le blab', u'le dizzily', u'le horrifying', u'le psycho', u'le sensational', u'lead', u'lead performance', u'leap', u'leap pinnacle', u'least', u'least rrb', u'leave', u'leave much', u'leave wondering', u'lecture', u'lecture confrontation', u'lee', u'lee writer', u'legged', u'legged freak', u'length', u'length film', u'let', u'let brush', u'letting', u'letting sleeping', u'lie', u'life', u'life celebrated', u'life clever', u'life different', u'light', u'light errol', u'like', u'like another', u'like drive', u'like experimental', u'like fatal', u'like going', u'like le', u'like light', u'like loosely', u'like moonlight', u'like movie', u'like reading', u'like satire', u'like series', u'like smoke', u'like state', u'like surge', u'like vulgar', u'like weird', u'like woman', u'like work', u'like world', u'line', u'line miss', u'list', u'little', u'little recommend', u'little sense', u'live', u'live exalted', u'living', u'living mug', u'look', u'look hollywood', u'look like', u'looking', u'looking common', u'loony', u'loony melodramatic', u'loosely', u'loosely connected', u'losing', u'losing cause', u'lot', u'lot chimp', u'lot fun', u'lot richer', u'lot running', u'lottery', u'lottery drawing', u'love', u'love cinema', u'love much', u'love myth', u'love song', u'love story', u'lovefest', u'low', u'low budget', u'lrb', u'lrb cho', u'lrb emotionally', u'lrb funny', u'lrb green', u'lrb rrb', u'lrb scherfig', u'lrb shakespeare', u'lrb sophomoric', u'lrb though', u'lrb ultimately', u'lunatic', u'lunch', u'lunch rush', u'lurid', u'lurid fiction', u'lush', u'lush enveloping', u'macabre', u'macabre stylized', u'maddening', u'made', u'made emotionally', u'made mamet', u'made movie', u'made old', u'madonna', u'madonna give', u'magic', u'magic realism', u'mainland', u'mainland setting', u'major', u'major problem', u'make', u'make big', u'make eight', u'make glacial', u'make oddest', u'make rather', u'make second', u'make seem', u'make something', u'make strong', u'make teeth', u'maker', u'maker serve', u'making', u'making le', u'making one', u'malcolm', u'malcolm lee', u'mamet', u'mamet airless', u'mamet house', u'man', u'man better', u'man dared', u'man know', u'manages', u'manages please', u'manipulative', u'manipulative whitewash', u'many', u'many thing', u'mark', u'mark pellington', u'martha', u'martha mostly', u'martial', u'martial art', u'martin', u'martin lawrence', u'mary', u'mary co', u'mary gaitskill', u'massoud', u'massoud story', u'masterful', u'masterful work', u'masterpiece', u'masterpiece theater', u'material', u'mawkish', u'mawkish self', u'may', u'may ploughing', u'mean', u'mean preach', u'meaning', u'meaning phrase', u'meaty', u'meaty subject', u'mediocre', u'mediocre movie', u'mediocre spiral', u'melodrama', u'melodramatic', u'melodramatic denouement', u'memorable', u'memorable cinematic', u'memorable zinger', u'memory', u'memory emotion', u'memory thoughtful', u'mention', u'mention apart', u'merchant', u'merchant work', u'mess', u'mess powerful', u'message', u'message time', u'middle', u'middle agers', u'middle hopeful', u'middle sad', u'midlife', u'midlife crisis', u'midnight', u'midnight flick', u'might', u'might enjoy', u'might inadvertently', u'might like', u'might look', u'mile', u'mile better', u'mill', u'mill action', u'mind', u'mind lrb', u'minded', u'minded film', u'minute', u'minute decent', u'minute movie', u'minute need', u'minute rest', u'miramax', u'miramax deep', u'miss', u'miss emotion', u'miss unfortunately', u'mixed', u'mixed result', u'modern', u'modern city', u'modern rut', u'modest', u'modest ultimately', u'mom', u'moment', u'moment history', u'moment make', u'mongrel', u'mongrel pep', u'monster', u'monster know', u'monsterous', u'monsterous one', u'monstrous', u'monstrous lunatic', u'monty', u'monty something', u'mood', u'mood love', u'moonlight', u'moonlight mile', u'moral', u'moral compromise', u'morris', u'morris focusing', u'mostly', u'mostly martha', u'mostly unsurprising', u'movement', u'movie', u'movie also', u'movie approach', u'movie avoid', u'movie becomes', u'movie center', u'movie despite', u'movie ever', u'movie experience', u'movie generates', u'movie good', u'movie improved', u'movie interested', u'movie leave', u'movie make', u'movie minute', u'movie otherwise', u'movie political', u'movie primary', u'movie progression', u'movie silly', u'movie start', u'movie thriller', u'movie try', u'movie ugly', u'movie way', u'moving', u'moving sometimes', u'moving without', u'mr', u'mr polanski', u'mr wong', u'much', u'much fresh', u'much fun', u'much hong', u'much music', u'much story', u'much taste', u'mug', u'mug shot', u'murder', u'murder shakespearean', u'music', u'music comic', u'myrtle', u'myrtle beach', u'mystery', u'mystery science', u'mystical', u'mystical tenderness', u'myth', u'mythic', u'mythic one', u'narcissistic', u'narcissistic achieving', u'narrative', u'narrative banality', u'narrative consistently', u'narrative expedience', u'narrative filmmaking', u'narrative form', u'narrative term', u'narratively', u'narratively trouble', u'natural', u'natural swimming', u'near', u'near future', u'nearly', u'nearly epic', u'nearly impossible', u'need', u'need le', u'neither', u'neither monsterous', u'neither point', u'nerve', u'nerve rattling', u'never', u'never play', u'never seems', u'never veers', u'new', u'new comedy', u'new meaning', u'new scene', u'new wound', u'new york', u'non', u'non techie', u'none', u'none amount', u'norris', u'norris grenade', u'nostalgic', u'nostalgic twisty', u'nothing', u'nothing amiable', u'nothing else', u'nothing run', u'noyce', u'noyce actor', u'number', u'number tumbleweed', u'observed', u'observed refreshingly', u'occasional', u'occasional smile', u'occasionally', u'occasionally amuses', u'occurs', u'occurs time', u'oddball', u'oddest', u'oddest couple', u'oedekerk', u'oedekerk realization', u'offer', u'offer flickering', u'offer opportunity', u'offering', u'offering case', u'often', u'old', u'old theme', u'old time', u'one', u'one best', u'one character', u'one considers', u'one cool', u'one crass', u'one hollywood', u'one lrb', u'one problem', u'one recent', u'one sided', u'one soon', u'one sweet', u'one thing', u'one year', u'open', u'open new', u'opera', u'opportunity', u'opportunity occasional', u'option', u'original', u'oscar', u'oscar size', u'otherwise', u'otherwise dull', u'otherwise tender', u'outnumber', u'outnumber hit', u'outtake', u'outtake theatrically', u'overboard', u'overboard loony', u'overeager', u'overeager spooky', u'overexposed', u'overexposed waste', u'owe', u'owe favor', u'pacing', u'pacing early', u'page', u'page memorable', u'paid', u'paid pay', u'paradiso', u'paradiso find', u'parallel', u'parallel might', u'paralyzed', u'paralyzed self', u'parent', u'parent coma', u'parody', u'parody play', u'particularly', u'particularly dark', u'particularly good', u'partly', u'partly homage', u'party', u'party watching', u'pastiche', u'pastiche caper', u'pat', u'pat make', u'pat storyline', u'path', u'path good', u'pay', u'pay see', u'pedigree', u'pedigree mongrel', u'pellington', u'pellington latest', u'people', u'people owe', u'people seen', u'pep', u'pep almost', u'peppering', u'peppering page', u'perfect', u'perfect performance', u'perfectly', u'perfectly entertaining', u'performance', u'performance absolute', u'performance capture', u'performance oscar', u'performance since', u'performance title', u'perhaps', u'perhaps cliche', u'permission', u'permission preemptive', u'perspective', u'perspective throw', u'perverse', u'perverse escapism', u'perverse pleasure', u'peter', u'peter fallon', u'pg', u'pg rating', u'phillip', u'phillip noyce', u'phrase', u'phrase fatal', u'pianist', u'pianist lack', u'piece', u'pinnacle', u'pinnacle pinnacle', u'pinnacle rous', u'place', u'place blame', u'place tatter', u'placing', u'placing parent', u'plainly', u'plainly dull', u'plausible', u'play', u'play dramatic', u'play like', u'played', u'played deeply', u'playing', u'playing narrative', u'playing usual', u'playwright', u'playwright poet', u'please', u'please intended', u'please mom', u'pleasure', u'pleasure watching', u'plodding', u'plodding mess', u'plot', u'plot complication', u'plot point', u'plot romantic', u'ploughing', u'ploughing furrow', u'poet', u'poet drinker', u'poetic', u'poetic far', u'poetry', u'poetry end', u'point', u'point degree', u'point view', u'point without', u'pointless', u'pointless extreme', u'polanski', u'polanski element', u'political', u'political ramification', u'pool', u'pool substitute', u'pool utterly', u'poor', u'poor editing', u'poorly', u'poorly delivered', u'pop', u'pop thriller', u'portrait', u'portrait screwed', u'positively', u'positively thrilling', u'post', u'post camp', u'postcard', u'postcard self', u'potent', u'potent riveting', u'pow', u'pow oedekerk', u'power', u'power visual', u'powerful', u'powerful moving', u'powerful people', u'preach', u'preach exclusively', u'precious', u'precious circumstance', u'predecessor', u'predecessor proud', u'preemptive', u'preemptive strike', u'preposterous', u'preposterous moment', u'pretty', u'pretty good', u'prevention', u'prevention rather', u'primary', u'primary goal', u'prisoner', u'prisoner lrb', u'probably', u'probably way', u'problem', u'problem trying', u'problem windtalker', u'processed', u'processed minute', u'producer', u'producer would', u'product', u'production', u'production would', u'prof', u'prof sometimes', u'proficiency', u'proficiency great', u'progression', u'progression rambling', u'promenade', u'promenade barely', u'proportion', u'proportion rooted', u'prose', u'prose screen', u'proud', u'prove', u'prove potent', u'provocative', u'provocative drama', u'psycho', u'psycho without', u'publishing', u'publishing world', u'pulp', u'pulp dangerous', u'pulpiness', u'pulpiness lurid', u'punch', u'punch line', u'purist', u'purist might', u'put', u'put battle', u'putting', u'putting weight', u'quality', u'quality nostalgic', u'quick', u'quick emotional', u'quiet', u'quiet american', u'quiet introspective', u'quiet power', u'quirky', u'quirky mixed', u'quotation', u'radical', u'radical action', u'rainbow', u'rainbow emotion', u'rambling', u'rambling incoherence', u'ramification', u'randomness', u'randomness usually', u'rapid', u'rapid leap', u'rare', u'rare capability', u'rather', u'rather convoluted', u'rather place', u'rather plausible', u'rather sweet', u'rating', u'rattling', u'rattling ride', u'ravaged', u'ravaged land', u'reading', u'reading bartlett', u'ready', u'ready go', u'real', u'real star', u'realism', u'realization', u'realization childhood', u'realization near', u'really', u'really anything', u'reason', u'reason exist', u'reason theater', u'recent', u'recent memory', u'recognizable', u'recommend', u'recommend snow', u'recommended', u'recommended viewing', u'record', u'record tenacious', u'reek', u'reek rot', u'reek script', u'refreshing', u'refreshingly', u'refreshingly natural', u'regular', u'regular shock', u'rehash', u'rehash several', u'reigen', u'reign', u'reign fire', u'relationship', u'relationship high', u'relationship struggle', u'relay', u'relay universal', u'released', u'released outtake', u'relic', u'relic bygone', u'relief', u'relief baseball', u'religious', u'religious civic', u'remain', u'remake', u'remake avenger', u'reminder', u'reminder tie', u'reno', u'reno make', u'report', u'report card', u'reporting', u'reporting number', u'resonant', u'resonant gem', u'resonant rainbow', u'rest', u'rest overexposed', u'result', u'result might', u'return', u'return narrative', u'revealed', u'revealed source', u'reveals', u'reveals effort', u'revelatory', u'revelatory narcissistic', u'rewrite', u'rewrite designed', u'rhapsodizes', u'richer', u'richer one', u'ride', u'ridley', u'right', u'right completely', u'right funny', u'right home', u'right promenade', u'right thinking', u'riveting', u'riveting unlikely', u'role', u'roll', u'romantic', u'romantic comedy', u'romantic date', u'romp', u'romp horror', u'room', u'room improvement', u'rooted', u'rooted sincere', u'rot', u'rot hack', u'rote', u'rote sentimentality', u'rous', u'rrb', u'rrb absorbing', u'rrb action', u'rrb adolescent', u'rrb amazing', u'rrb comedy', u'rrb deepest', u'rrb history', u'rrb made', u'rrb movie', u'rrb romp', u'run', u'run life', u'run mill', u'runaway', u'runaway success', u'running', u'running around', u'rush', u'rush diner', u'russian', u'russian history', u'rut', u'rut narrative', u'sad', u'sad middle', u'saddam', u'saddam hussein', u'sanguine', u'sanguine title', u'sarah', u'sarah harrison', u'satire', u'satisfying', u'satisfying david', u'saved', u'saved film', u'say', u'say growing', u'say might', u'say something', u'say way', u'scarcely', u'scarcely worth', u'scattered', u'scattered film', u'scene', u'scene interesting', u'scene poorly', u'scherfig', u'scherfig rrb', u'schindler', u'schindler list', u'schnitzler', u'schnitzler reigen', u'school', u'school swimming', u'sci', u'sci fi', u'science', u'science theater', u'scientific', u'scientific law', u'scrapbook', u'scrapbook living', u'scrapbook oddball', u'scrape', u'scrape bottom', u'scratch', u'scratch hole', u'screaming', u'screaming death', u'screen', u'screen postcard', u'screen remake', u'screen version', u'screenplay', u'screenplay james', u'screenwriter', u'screenwriter usually', u'screwed', u'screwed man', u'script', u'script aim', u'script endless', u'script error', u'script rewrite', u'scruffy', u'scruffy giannini', u'seamless', u'seamless sumptuous', u'second', u'second guess', u'see', u'see point', u'seeking', u'seem', u'seem hobby', u'seems', u'seems aware', u'seems coasting', u'seems mind', u'seen', u'seen eye', u'self', u'self glorification', u'self glorified', u'self indulgent', u'self parody', u'sensational', u'sensational true', u'sense', u'sense going', u'sense movie', u'sentimentality', u'sentimentality mystical', u'sequel', u'sequel fails', u'sequence', u'sequence like', u'series', u'series escapade', u'series vignette', u'serious', u'serious minded', u'serious say', u'serve', u'serve cliche', u'serve whatever', u'set', u'set tone', u'setting', u'several', u'several old', u'sex', u'sex joke', u'sexual', u'sexual violence', u'sexy', u'sexy violent', u'shainberg', u'shainberg adaptation', u'shakespeare', u'shakespeare rrb', u'shakespearean', u'shakespearean tragedy', u'sharp', u'sharp movie', u'shelf', u'shelf couple', u'shell', u'shell game', u'shiver', u'shiver inducing', u'shock', u'shock bout', u'shock curiosity', u'shocker', u'shocker playing', u'short', u'short story', u'short wonderful', u'shot', u'shoulder', u'shoulder playing', u'show', u'show good', u'show slice', u'show well', u'shyamalan', u'shyamalan stop', u'sided', u'sided theme', u'signal', u'signal film', u'silly', u'silly beyond', u'silly lrb', u'silly rather', u'silly rrb', u'silly would', u'simply', u'simply movie', u'simply tired', u'since', u'since abel', u'sincere', u'sincere performance', u'single', u'single stroke', u'sitting', u'sitting one', u'size', u'size house', u'sketch', u'sketch neither', u'skin', u'skin man', u'skittish', u'skittish new', u'slapstick', u'slapstick instrument', u'sleek', u'sleek arty', u'sleeping', u'sleeping dog', u'slice', u'slice life', u'slip', u'slip modern', u'smart', u'smart new', u'smart provocative', u'smile', u'smile chuckle', u'smoke', u'smoke signal', u'sneaky', u'sneaky feel', u'snow', u'snow dog', u'soap', u'soap opera', u'society', u'society place', u'solid', u'solid achievement', u'solution', u'solution another', u'solving', u'solving one', u'something', u'something bigger', u'something different', u'something even', u'something mary', u'something serious', u'something subject', u'sometimes', u'sometimes dream', u'song', u'song movie', u'soon', u'soon action', u'soon dark', u'soothe', u'soothe break', u'sophomoric', u'sophomoric rrb', u'sort', u'sort romantic', u'sounding', u'sounding like', u'source', u'source high', u'source spiritual', u'spalding', u'spalding gray', u'spectacularly', u'spectacularly well', u'speed', u'speed explosion', u'spider', u'spider man', u'spielberg', u'spielberg realization', u'spielberg schindler', u'spiral', u'spiral downward', u'spiritual', u'spiritual survival', u'spirituality', u'spirituality powerful', u'splash', u'spooky', u'spooky subtly', u'stale', u'stale uninspired', u'star', u'star reign', u'start', u'start drag', u'start fall', u'start finish', u'start mediocre', u'state', u'steer', u'steer emphasizes', u'steven', u'steven shainberg', u'steven spielberg', u'still', u'still beyond', u'still consoled', u'still good', u'still like', u'still looking', u'still option', u'still sweet', u'stirring', u'stirring visual', u'stoner', u'stoner midnight', u'stooping', u'stooping base', u'stop', u'stop trying', u'story', u'story alone', u'story brilliantly', u'story epic', u'story involving', u'story lot', u'story sanguine', u'story sarah', u'story take', u'storyline', u'storyline precious', u'storytelling', u'storytelling lrb', u'strangeness', u'strangeness inexorably', u'stream', u'stream consciousness', u'strike', u'string', u'string acting', u'stroke', u'strong', u'strong case', u'strong theme', u'structure', u'structure arthur', u'struggle', u'struggle furiously', u'study', u'study exists', u'study gamble', u'stuff', u'stumble', u'stumble relationship', u'style', u'style flash', u'stylized', u'stylized swedish', u'subject', u'subject drawn', u'subject willingness', u'substitutable', u'substitutable force', u'substitute', u'substitute bathtub', u'subtly', u'subtly love', u'succeed', u'success', u'success first', u'sudden', u'sudden lunch', u'sudden turn', u'summer', u'summer blockbuster', u'summer diversion', u'summer good', u'summer hopefully', u'sumptuous', u'sumptuous stream', u'sunday', u'sunday grace', u'sure', u'sure filmmaker', u'surge', u'surge swirling', u'surprisingly', u'surprisingly affecting', u'surprisingly solid', u'surreal', u'surreal resonant', u'survival', u'suspect', u'suspect kind', u'suspect would', u'swaying', u'swaying back', u'swedish', u'swedish fillm', u'sweet', u'sweet even', u'sweet modest', u'swimfan', u'swimfan like', u'swimming', u'swimming get', u'swimming pool', u'swinging', u'swinging film', u'swirling', u'swirling rapid', u'tackled', u'tackled meaty', u'tagline', u'tagline definite', u'take', u'take clunky', u'take one', u'take sudden', u'take totally', u'taking', u'taking important', u'tarantula', u'tarantula low', u'tartakovsky', u'tartakovsky team', u'taste', u'tatter', u'team', u'team freakish', u'techie', u'techie enjoy', u'technical', u'technical proficiency', u'teen', u'teen gross', u'teeth', u'teeth hurt', u'tell', u'tell fascinating', u'tenacious', u'tenacious humane', u'tender', u'tender movement', u'tenderness', u'tenderness becomes', u'tension', u'tension beneath', u'term', u'term inoffensive', u'terror', u'terror hero', u'thanks', u'thanks largely', u'theater', u'theater beyond', u'theater guy', u'theater sketch', u'theatre', u'theatre graced', u'theatrically', u'theatrically used', u'theme', u'theme capped', u'theme familial', u'theme lawrence', u'thick', u'thick wit', u'thing', u'thing happen', u'thing stoner', u'thing wild', u'thinking', u'thinking film', u'though', u'though film', u'though le', u'thought', u'thought right', u'thoughtful', u'thoughtful film', u'thoughtful surprisingly', u'threatens', u'threatens get', u'three', u'three one', u'thriller', u'thriller keep', u'thriller kooky', u'thriller movie', u'thrilling', u'thrilling combination', u'throw', u'throw path', u'thud', u'thud bottom', u'tian', u'tian zhuangzhuang', u'tie', u'tie bind', u'tie spirituality', u'time', u'time cheap', u'time frame', u'time movie', u'time sitting', u'time visual', u'time windtalker', u'tirade', u'tirade knock', u'tired', u'tired fighting', u'title', u'title character', u'tolstoy', u'tolstoy groupie', u'tone', u'tone right', u'tone summer', u'totally', u'totally unexpected', u'toward', u'toward closure', u'toxic', u'toxic chemical', u'tragedy', u'tragedy juicy', u'tragedy record', u'tragedy smart', u'transforms', u'transforms one', u'transparent', u'transparent script', u'tricky', u'tricky satisfying', u'triumph', u'triumph film', u'triumphantly', u'triumphantly return', u'trouble', u'trouble every', u'true', u'true crime', u'truest', u'truest sense', u'try', u'try avoid', u'try hard', u'trying', u'trying distract', u'trying dupe', u'trying find', u'trying please', u'tryingly', u'tryingly title', u'tsai', u'tsai may', u'tumbleweed', u'tumbleweed blowing', u'turn', u'turn devolves', u'turpin', u'tv', u'tv movie', u'twisty', u'twisty yarn', u'two', u'two skittish', u'ugly', u'ugly incomprehensible', u'ugly look', u'ultimately', u'ultimately losing', u'ultimately make', u'ultimately silly', u'ultimately victim', u'ultimately winning', u'ultra', u'ultra cheesy', u'uncluttered', u'uncluttered resonant', u'undergoing', u'undergoing midlife', u'understand', u'understand delicate', u'uneven', u'uneven lot', u'unexpected', u'unexpected direction', u'unfocused', u'unfocused bagatelle', u'unfortunately', u'unfortunately outnumber', u'unimaginative', u'unimaginative probably', u'uninspired', u'unintentional', u'unintentional parallel', u'universal', u'universal point', u'unless', u'unless one', u'unlikely', u'unlikely story', u'unnamed', u'unnamed easily', u'unpredictable', u'unpredictable character', u'unprepared', u'unsettling', u'unsettling experience', u'unsettling image', u'unsettling memorable', u'unsurprising', u'unsurprising still', u'uplifting', u'uplifting moving', u'upon', u'upon still', u'upscale', u'upscale audience', u'used', u'used film', u'usual', u'usual bad', u'usually', u'usually achieved', u'usually come', u'utterly', u'utterly incompetent', u'vapid', u'vapid actor', u'vaudeville', u'vaudeville show', u'veers', u'veers comic', u'veiling', u'veiling tension', u'version', u'version quiet', u'victim', u'victim rrb', u'view', u'view compelling', u'viewer', u'viewer taking', u'viewing', u'viewing courage', u'vignette', u'vignette clip', u'villain', u'villain lack', u'vincent', u'vincent gallo', u'violence', u'violence keep', u'violent', u'violent graphic', u'violent self', u'violent vulgar', u'virtue', u'virtue hold', u'visual', u'visual charm', u'visual flair', u'visual sequence', u'visually', u'visually masterful', u'visually ugly', u'vulgar', u'vulgar forgettably', u'waking', u'waking reno', u'wallace', u'wallace get', u'wallflower', u'want', u'want nothing', u'war', u'war movie', u'war ravaged', u'waste', u'waste film', u'watching', u'watching disney', u'watching host', u'wax', u'wax poetic', u'way', u'way extravagant', u'way gently', u'way rote', u'way saved', u'way succeed', u'wear', u'wear welcome', u'weight', u'weight world', u'weird', u'weird masterpiece', u'weirdly', u'weirdly engaging', u'weirdo', u'weirdo role', u'welcome', u'welcome relief', u'welcome tryingly', u'well', u'well cinematographer', u'well constructed', u'well heed', u'well made', u'well shiver', u'west', u'whatever', u'whatever terror', u'whenever', u'whenever threatens', u'whitewash', u'whole', u'whole film', u'whose', u'whose hero', u'wild', u'wild film', u'wild west', u'wild wild', u'wilde', u'wilde wit', u'will', u'will impossible', u'williams', u'williams interesting', u'willingness', u'wind', u'wind revelatory', u'windtalker', u'windtalker bulk', u'windtalker good', u'winning', u'winning story', u'wisecracking', u'wisecracking mystery', u'wit', u'wit actor', u'wit play', u'within', u'within wallflower', u'without', u'without lecture', u'without making', u'without placing', u'without stooping', u'wo', u'wo disappointed', u'woman', u'woman inspired', u'wonderful', u'wonderful big', u'wondering', u'wondering character', u'wong', u'wong mood', u'work', u'work artist', u'work quiet', u'work spectacularly', u'work start', u'work suspect', u'workshop', u'workshop exercise', u'world', u'world carry', u'world film', u'world offering', u'world shoulder', u'worth', u'worth mention', u'worth seeking', u'worth taking', u'would', u'would disagree', u'would funnier', u'would hard', u'would still', u'would well', u'wound', u'writer', u'writer director', u'writer ed', u'writer john', u'writer slip', u'written', u'written flatly', u'wrong', u'wrong character', u'yarn', u'yarn keep', u'year', u'year far', u'year russian', u'year weirdly', u'yet', u'yet instantly', u'york', u'york middle', u'young', u'young actress', u'young fit', u'young romantic', u'youth', u'youth remain', u'zhuangzhuang', u'zhuangzhuang triumphantly', u'zinger']\n(5000, 2984)\n"
     ]
    }
   ],
   "source": [
    "#Feature Extraction\n",
    "#Split train-test set\n",
    "cv = CountVectorizer(max_features = 3000,ngram_range=(1, 2))\n",
    "x__train = x__test=cv.fit_transform(vocabulary).toarray()\n",
    "y = training_set.iloc[:, 2].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(x__train, y, test_size = 0.20, random_state = 0)\n",
    "print(cv.get_feature_names())\n",
    "print(x__train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2000)\n"
     ]
    }
   ],
   "source": [
    "#Feature Selection\n",
    "X_new = SelectKBest(chi2, k=2000).fit_transform(x__train, y)\n",
    "print(X_new.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n('Accuracy:', 0.70499999999999996)\n('F1 score:', 0.52445614382346795)\n('Recall:', 0.61804500569601883)\n('Precision:', 0.4822423195047511)\n1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n('Accuracy:', 0.69499999999999995)\n('F1 score:', 0.51916498866443717)\n('Recall:', 0.6051939508875348)\n('Precision:', 0.4785509107375624)\n1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n('Accuracy:', 0.69799999999999995)\n('F1 score:', 0.51829395889944896)\n('Recall:', 0.59095890310006394)\n('Precision:', 0.48201911883004794)\n1400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n('Accuracy:', 0.68799999999999994)\n('F1 score:', 0.50449635501327172)\n('Recall:', 0.57108197505659264)\n('Precision:', 0.46988635847850679)\n1600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n('Accuracy:', 0.68400000000000005)\n('F1 score:', 0.50313086943845353)\n('Recall:', 0.56619871921323528)\n('Precision:', 0.46938624302696963)\n1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n('Accuracy:', 0.68200000000000005)\n('F1 score:', 0.50202168488294008)\n('Recall:', 0.56366164097154847)\n('Precision:', 0.4687364037385498)\n2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n('Accuracy:', 0.68000000000000005)\n('F1 score:', 0.50121952263372582)\n('Recall:', 0.55767340557646361)\n('Precision:', 0.46955934432213831)\n2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n('Accuracy:', 0.67400000000000004)\n('F1 score:', 0.49786053941765795)\n('Recall:', 0.54731218107920043)\n('Precision:', 0.46889308676099162)\n2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n('Accuracy:', 0.67800000000000005)\n('F1 score:', 0.50403643487178074)\n('Recall:', 0.55265227734651867)\n('Precision:', 0.47499200845883688)\n2600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n('Accuracy:', 0.68200000000000005)\n('F1 score:', 0.50732019922178073)\n('Recall:', 0.55632195180965893)\n('Precision:', 0.4780171596648789)\n2800\n"
     ]
    }
   ],
   "source": [
    "#Find best k\n",
    "for k in range(1000,3000,200):\n",
    " X_new = SelectKBest(chi2, k).fit_transform(x__train, y)\n",
    " X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.20, random_state = 0)\n",
    " classifier = svm.LinearSVC()\n",
    " classifier.fit(X_train, y_train)\n",
    " y_pred = classifier.predict(X_test)\n",
    " print(\"SVM Classifier\")\n",
    " print( 'Accuracy:', accuracy_score(y_pred,y_test))\n",
    " print( 'F1 score:', f1_score(y_pred,y_test,average=\"macro\"))\n",
    " print ('Recall:', recall_score(y_pred,y_test,average=\"macro\"))\n",
    " print ('Precision:', precision_score(y_pred,y_test,average=\"macro\"))\n",
    " print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Weighting\n",
    "vectorizer = TfidfVectorizer(max_df=0.003,min_df=0.001,ngram_range=(1,2))\n",
    "x__train = x__test=vectorizer.fit_transform(vocabulary).toarray()\n",
    "y = training_set.iloc[:, 2].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(x__train, y, test_size = 0.20, random_state = 0)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(x__train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes Classifier\n('Accuracy:', 63.800000000000004)\n('F1 score:', 51.590254570902857)\n('Recall:', 51.869273239596517)\n('Precision:', 51.677976748791579)\n"
     ]
    }
   ],
   "source": [
    "#Bayes Classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Bayes Classifier\")\n",
    "print( 'Accuracy:', accuracy_score(y_pred,y_test)*100)\n",
    "print( 'F1 score:', f1_score(y_pred,y_test,average=\"macro\")*100)\n",
    "print ('Recall:', recall_score(y_pred,y_test,average=\"macro\")*100)\n",
    "print ('Precision:', precision_score(y_pred,y_test,average=\"macro\")*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree\n('Accuracy:', 65.900000000000006)\n('F1 score:', 49.767081897599056)\n('Recall:', 52.625833668350971)\n('Precision:', 47.875072291435636)\n"
     ]
    }
   ],
   "source": [
    "#Decision tree\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Decision tree\")\n",
    "print( 'Accuracy:', accuracy_score(y_pred,y_test)*100)\n",
    "print( 'F1 score:', f1_score(y_pred,y_test,average=\"macro\")*100)\n",
    "print ('Recall:', recall_score(y_pred,y_test,average=\"macro\")*100)\n",
    "print ('Precision:', precision_score(y_pred,y_test,average=\"macro\")*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network\n('Accuracy:', 58.199999999999996)\n('F1 score:', 23.991962002192182)\n('Recall:', 21.059624904675118)\n('Precision:', 29.143508372052253)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\nC:\\Python27\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "classifier = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Neural Network\")\n",
    "print( 'Accuracy:', accuracy_score(y_pred,y_test)*100)\n",
    "print( 'F1 score:', f1_score(y_pred,y_test,average=\"macro\")*100)\n",
    "print ('Recall:', recall_score(y_pred,y_test,average=\"macro\")*100)\n",
    "print ('Precision:', precision_score(y_pred,y_test,average=\"macro\")*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-NN Classifier\n('Accuracy:', 65.5)\n('F1 score:', 45.763639217650024)\n('Recall:', 63.891771149253941)\n('Precision:', 41.343685869892525)\n"
     ]
    }
   ],
   "source": [
    "#3-NN Classifier\n",
    "classifier= KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"3-NN Classifier\")\n",
    "print( 'Accuracy:', accuracy_score(y_pred,y_test)*100)\n",
    "print( 'F1 score:', f1_score(y_pred,y_test,average=\"macro\")*100)\n",
    "print ('Recall:', recall_score(y_pred,y_test,average=\"macro\")*100)\n",
    "print ('Precision:', precision_score(y_pred,y_test,average=\"macro\")*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n('Accuracy:', 68.200000000000003)\n('F1 score:', 50.732019922178075)\n('Recall:', 55.632195180965894)\n('Precision:', 47.80171596648789)\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier\n",
    "classifier = svm.LinearSVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"SVM Classifier\")\n",
    "print( 'Accuracy:', accuracy_score(y_pred,y_test)*100)\n",
    "print( 'F1 score:', f1_score(y_pred,y_test,average=\"macro\")*100)\n",
    "print ('Recall:', recall_score(y_pred,y_test,average=\"macro\")*100)\n",
    "print ('Precision:', precision_score(y_pred,y_test,average=\"macro\")*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier\n('Accuracy:', 68.0)\n('F1 score:', 50.018117244943817)\n('Recall:', 67.307912845496944)\n('Precision:', 44.3327868780068)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Logistic Regression Classifier\")\n",
    "print( 'Accuracy:', accuracy_score(y_pred,y_test)*100)\n",
    "print( 'F1 score:', f1_score(y_pred,y_test,average=\"macro\")*100)\n",
    "print ('Recall:', recall_score(y_pred,y_test,average=\"macro\")*100)\n",
    "print ('Precision:', precision_score(y_pred,y_test,average=\"macro\")*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
